{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet') # download for lemmatization\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, fbeta_score, recall_score, classification_report, accuracy_score, precision_score, make_scorer, precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from workspace_utils import active_session\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///disaster_data.db')\n",
    "df = pd.read_sql(\"SELECT * FROM disaster_data\",engine)\n",
    "# df.head()\n",
    "X = df.message.values\n",
    "Y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\",\" \",text.lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect',CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('clf',MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only 10% of data for fitting using GridSearchCV so that it's faster\n",
    "# train = np.concatenate((X_train, y_train), axis=1)\n",
    "# X_train_d = X_train[:,np.newaxis]\n",
    "# train = np.hstack((X_train, y_train))\n",
    "\n",
    "# train_sample = train.sample(frac=0.1, replace=False, random_state=None, axis=0)\n",
    "\n",
    "number_of_rows = X_train.shape[0]\n",
    "\n",
    "# np.random.seed(123) # uncomment if we want repeatable results\n",
    "random_rows = np.random.choice(number_of_rows, size=int(0.10*number_of_rows), replace=False)\n",
    "\n",
    "X_train_sample = X_train[random_rows] # this is numpy ndarray\n",
    "y_train_sample = y_train.iloc[random_rows,:] # this is pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline.fit(X_train_sample,y_train_sample) # for now, do only with a subset, to compare to tuned model, which needs subset to run in reasonable time\n",
    "\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.45      0.52      1557\n",
      "          1       0.84      0.91      0.88      4950\n",
      "\n",
      "avg / total       0.79      0.80      0.79      6507\n",
      "\n",
      "Accuracy:  0.802213001383 \n",
      "\n",
      "request\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94      5399\n",
      "          1       0.81      0.45      0.58      1108\n",
      "\n",
      "avg / total       0.88      0.89      0.88      6507\n",
      "\n",
      "Accuracy:  0.888735208237 \n",
      "\n",
      "offer\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6476\n",
      "          1       0.00      0.00      0.00        31\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6507\n",
      "\n",
      "Accuracy:  0.9952358998 \n",
      "\n",
      "aid_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.85      0.80      3784\n",
      "          1       0.75      0.62      0.68      2723\n",
      "\n",
      "avg / total       0.75      0.75      0.75      6507\n",
      "\n",
      "Accuracy:  0.752266789611 \n",
      "\n",
      "medical_help\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      6004\n",
      "          1       0.58      0.09      0.15       503\n",
      "\n",
      "avg / total       0.90      0.92      0.90      6507\n",
      "\n",
      "Accuracy:  0.924542800061 \n",
      "\n",
      "medical_products\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6166\n",
      "          1       0.76      0.11      0.19       341\n",
      "\n",
      "avg / total       0.94      0.95      0.93      6507\n",
      "\n",
      "Accuracy:  0.951436914093 \n",
      "\n",
      "search_and_rescue\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      6329\n",
      "          1       0.54      0.04      0.07       178\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6507\n",
      "\n",
      "Accuracy:  0.972798524666 \n",
      "\n",
      "security\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6386\n",
      "          1       0.00      0.00      0.00       121\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6507\n",
      "\n",
      "Accuracy:  0.980482557246 \n",
      "\n",
      "military\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6267\n",
      "          1       0.63      0.07      0.13       240\n",
      "\n",
      "avg / total       0.95      0.96      0.95      6507\n",
      "\n",
      "Accuracy:  0.964192408176 \n",
      "\n",
      "child_alone\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6507\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6507\n",
      "\n",
      "Accuracy:  1.0 \n",
      "\n",
      "water\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      6090\n",
      "          1       0.88      0.30      0.45       417\n",
      "\n",
      "avg / total       0.95      0.95      0.94      6507\n",
      "\n",
      "Accuracy:  0.952820039957 \n",
      "\n",
      "food\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      5758\n",
      "          1       0.86      0.47      0.61       749\n",
      "\n",
      "avg / total       0.93      0.93      0.92      6507\n",
      "\n",
      "Accuracy:  0.930228984171 \n",
      "\n",
      "shelter\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97      5952\n",
      "          1       0.82      0.35      0.49       555\n",
      "\n",
      "avg / total       0.93      0.94      0.93      6507\n",
      "\n",
      "Accuracy:  0.938220378054 \n",
      "\n",
      "clothing\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6410\n",
      "          1       0.81      0.18      0.29        97\n",
      "\n",
      "avg / total       0.99      0.99      0.98      6507\n",
      "\n",
      "Accuracy:  0.987090825265 \n",
      "\n",
      "money\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6375\n",
      "          1       0.56      0.04      0.07       132\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6507\n",
      "\n",
      "Accuracy:  0.97986783464 \n",
      "\n",
      "missing_people\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6430\n",
      "          1       0.00      0.00      0.00        77\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6507\n",
      "\n",
      "Accuracy:  0.988012909175 \n",
      "\n",
      "refugees\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6293\n",
      "          1       0.64      0.14      0.22       214\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6507\n",
      "\n",
      "Accuracy:  0.969110189027 \n",
      "\n",
      "death\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6188\n",
      "          1       0.77      0.09      0.17       319\n",
      "\n",
      "avg / total       0.95      0.95      0.94      6507\n",
      "\n",
      "Accuracy:  0.954203165821 \n",
      "\n",
      "other_aid\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93      5665\n",
      "          1       0.56      0.04      0.08       842\n",
      "\n",
      "avg / total       0.83      0.87      0.82      6507\n",
      "\n",
      "Accuracy:  0.871830336561 \n",
      "\n",
      "infrastructure_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      6084\n",
      "          1       0.20      0.00      0.01       423\n",
      "\n",
      "avg / total       0.89      0.93      0.90      6507\n",
      "\n",
      "Accuracy:  0.934071000461 \n",
      "\n",
      "transport\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6218\n",
      "          1       0.75      0.08      0.15       289\n",
      "\n",
      "avg / total       0.95      0.96      0.94      6507\n",
      "\n",
      "Accuracy:  0.958045182112 \n",
      "\n",
      "buildings\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6194\n",
      "          1       0.71      0.09      0.16       313\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6507\n",
      "\n",
      "Accuracy:  0.954510527125 \n",
      "\n",
      "electricity\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6374\n",
      "          1       0.67      0.03      0.06       133\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6507\n",
      "\n",
      "Accuracy:  0.97986783464 \n",
      "\n",
      "tools\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6462\n",
      "          1       0.00      0.00      0.00        45\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6507\n",
      "\n",
      "Accuracy:  0.993084370678 \n",
      "\n",
      "hospitals\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6439\n",
      "          1       0.00      0.00      0.00        68\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6507\n",
      "\n",
      "Accuracy:  0.989549715691 \n",
      "\n",
      "shops\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6474\n",
      "          1       0.00      0.00      0.00        33\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6507\n",
      "\n",
      "Accuracy:  0.994928538497 \n",
      "\n",
      "aid_centers\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6423\n",
      "          1       0.00      0.00      0.00        84\n",
      "\n",
      "avg / total       0.97      0.99      0.98      6507\n",
      "\n",
      "Accuracy:  0.987090825265 \n",
      "\n",
      "other_infrastructure\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6231\n",
      "          1       0.33      0.01      0.01       276\n",
      "\n",
      "avg / total       0.93      0.96      0.94      6507\n",
      "\n",
      "Accuracy:  0.957276778854 \n",
      "\n",
      "weather_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91      4734\n",
      "          1       0.84      0.64      0.72      1773\n",
      "\n",
      "avg / total       0.87      0.87      0.86      6507\n",
      "\n",
      "Accuracy:  0.868449362225 \n",
      "\n",
      "floods\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97      5969\n",
      "          1       0.85      0.34      0.48       538\n",
      "\n",
      "avg / total       0.94      0.94      0.93      6507\n",
      "\n",
      "Accuracy:  0.940064545874 \n",
      "\n",
      "storm\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      5921\n",
      "          1       0.76      0.42      0.54       586\n",
      "\n",
      "avg / total       0.93      0.94      0.93      6507\n",
      "\n",
      "Accuracy:  0.935761487629 \n",
      "\n",
      "fire\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6440\n",
      "          1       1.00      0.03      0.06        67\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6507\n",
      "\n",
      "Accuracy:  0.990010757646 \n",
      "\n",
      "earthquake\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      5914\n",
      "          1       0.89      0.70      0.78       593\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6507\n",
      "\n",
      "Accuracy:  0.964653450131 \n",
      "\n",
      "cold\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6371\n",
      "          1       0.88      0.10      0.18       136\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6507\n",
      "\n",
      "Accuracy:  0.980943599201 \n",
      "\n",
      "other_weather\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6172\n",
      "          1       0.41      0.05      0.09       335\n",
      "\n",
      "avg / total       0.92      0.95      0.93      6507\n",
      "\n",
      "Accuracy:  0.947441217151 \n",
      "\n",
      "direct_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91      5204\n",
      "          1       0.75      0.31      0.44      1303\n",
      "\n",
      "avg / total       0.83      0.84      0.81      6507\n",
      "\n",
      "Accuracy:  0.841247886891 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# f1_score = fbeta_score(y_test,predicted,beta=1)\n",
    "# precision = fbeta_score(y_test,predicted,beta=0)\n",
    "# recall =  recall_score(y_test,predicted)\n",
    "\n",
    "# for i in range(y_test.shape[1]):\n",
    "#     print(classification_report(y_test.iloc[:,i],predicted[:,i]))\n",
    "\n",
    "# print(classification_report(y_test.values,predicted,target_names=Y.columns.values))\n",
    "\n",
    "category_names = Y.columns.values\n",
    "for i, c in enumerate(category_names): \n",
    "    print(c)\n",
    "#     if i==1:\n",
    "#         test=classification_report(y_test.iloc[:,i], predicted[:,i],output_dict=True)\n",
    "    print(classification_report(y_test.iloc[:,i], predicted[:,i])) # the averages given here are weighted\n",
    "    print('Accuracy: ', accuracy_score(y_test.iloc[:,i],predicted[:,i]), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "(0.7877008798926457, 0.8022130013831259, 0.79058655121166244, None) \n",
      "\n",
      "request\n",
      "(0.88248752420835974, 0.88873520823728291, 0.87506156967090343, None) \n",
      "\n",
      "offer\n",
      "(0.99049449625114405, 0.99523589980021521, 0.99285953741141386, None) \n",
      "\n",
      "aid_related\n",
      "(0.75159316004825505, 0.75226678961118798, 0.74786075388464002, None) \n",
      "\n",
      "medical_help\n",
      "(0.9015628059202655, 0.92454280006147227, 0.89823411170113043, None) \n",
      "\n",
      "medical_products\n",
      "(0.9425595862825672, 0.95143691409251574, 0.93381853238229007, None) \n",
      "\n",
      "search_and_rescue\n",
      "(0.96176286055676807, 0.97279852466574457, 0.96122420385687368, None) \n",
      "\n",
      "security\n",
      "(0.96313822651487913, 0.98048255724604272, 0.97173300389124373, None) \n",
      "\n",
      "military\n",
      "(0.95319520573285765, 0.96419240817581064, 0.95020877379628366, None) \n",
      "\n",
      "child_alone\n",
      "(1.0, 1.0, 1.0, None) \n",
      "\n",
      "water\n",
      "(0.94977917282276858, 0.9528200399569694, 0.94185757365701073, None) \n",
      "\n",
      "food\n",
      "(0.92634874184573901, 0.93022898417089284, 0.92098668949839779, None) \n",
      "\n",
      "shelter\n",
      "(0.93236575116428377, 0.93822037805440295, 0.92662136225253822, None) \n",
      "\n",
      "clothing\n",
      "(0.98501017568194493, 0.98709082526509917, 0.98297167222265169, None) \n",
      "\n",
      "money\n",
      "(0.97183606943073297, 0.97986783463961891, 0.97118296402629223, None) \n",
      "\n",
      "missing_people\n",
      "(0.97647141192645948, 0.98801290917473494, 0.98220825695633041, None) \n",
      "\n",
      "refugees\n",
      "(0.96061924027534662, 0.96911018902720147, 0.95923687957208292, None) \n",
      "\n",
      "death\n",
      "(0.94619570276555054, 0.95420316582142306, 0.9368003914750006, None) \n",
      "\n",
      "other_aid\n",
      "(0.83433460016243677, 0.87183033656062703, 0.82116966826208504, None) \n",
      "\n",
      "infrastructure_related\n",
      "(0.88740772153378167, 0.93407100046104197, 0.90371124521931356, None) \n",
      "\n",
      "transport\n",
      "(0.94978763588722104, 0.95804518211157219, 0.94167492249913876, None)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "buildings\n",
      "(0.94411203973282209, 0.95451052712463502, 0.93752301593770859, None) \n",
      "\n",
      "electricity\n",
      "(0.97374930697732609, 0.97986783463961891, 0.97077005891292012, None) \n",
      "\n",
      "tools\n",
      "(0.98621656728438634, 0.9930843706777317, 0.98963855398558132, None) \n",
      "\n",
      "hospitals\n",
      "(0.97920863982373219, 0.98954971569079453, 0.98435201905345693, None) \n",
      "\n",
      "shops\n",
      "(0.98988279671578283, 0.99492853849700325, 0.99239925402197038, None) \n",
      "\n",
      "aid_centers\n",
      "(0.97434829732253458, 0.98709082526509917, 0.98067817025177595, None) \n",
      "\n",
      "other_infrastructure\n",
      "(0.93136311475717926, 0.95727677885354234, 0.93727717603729865, None) \n",
      "\n",
      "weather_related\n",
      "(0.86633188210705658, 0.86844936222529578, 0.8620881644373003, None) \n",
      "\n",
      "floods\n",
      "(0.93521097370054551, 0.9400645458736745, 0.92794475890933859, None) \n",
      "\n",
      "storm\n",
      "(0.92825974089355645, 0.93576148762870759, 0.92737985861441186, None) \n",
      "\n",
      "fire\n",
      "(0.99011057328789309, 0.99001075764561242, 0.98533075893530453, None) \n",
      "\n",
      "earthquake\n",
      "(0.9630679677956645, 0.96465345013062853, 0.96273894809298688, None) \n",
      "\n",
      "cold\n",
      "(0.97898500547044875, 0.98094359920086061, 0.97351023201487019, None) \n",
      "\n",
      "other_weather\n",
      "(0.92321522290115765, 0.94744121715076068, 0.92750431167051506, None) \n",
      "\n",
      "direct_report\n",
      "(0.82976636635910705, 0.84124788689104046, 0.81359016119475613, None) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = dict()\n",
    "for i, c in enumerate(category_names): \n",
    "    print(c)\n",
    "    metrics[c] = precision_recall_fscore_support(y_test.iloc[:,i], predicted[:,i],average='weighted')\n",
    "    print(metrics[c],'\\n')\n",
    "#     print('Accuracy: ', accuracy_score(y_test.iloc[:,i],predicted[:,i]), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79058655121166244"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "metrics['related'][2] # f score of 'related' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is cleaner (but only gives values for positive class)\n",
    "# print(classification_report(y_test, predicted, target_names=Y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following doesn't give averages either\n",
    "category_names = Y.columns.values\n",
    "def get_metrics_summary(y_test,y_pred):\n",
    "    metrics_summary = pd.DataFrame(index = category_names, columns = ['accuracy', 'precision', 'recall', 'f-1_score'])\n",
    "    for i, c in enumerate(category_names): \n",
    "        metrics_summary.loc[c,'accuracy'] = accuracy_score(y_test.iloc[:,i],y_pred[:,i])\n",
    "        metrics_summary.loc[c,'precision'] = precision_score(y_test.iloc[:,i],y_pred[:,i])\n",
    "        metrics_summary.loc[c,'recall'] = recall_score(y_test.iloc[:,i],y_pred[:,i])\n",
    "        metrics_summary.loc[c,'f-1_score'] = fbeta_score(y_test.iloc[:,i],y_pred[:,i],beta=1)\n",
    "\n",
    "    metrics_summary.loc['average'] = metrics_summary.mean(axis=0)\n",
    "    \n",
    "    return metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_summary_1 = get_metrics_summary(y_test,predicted)\n",
    "# metrics_summary_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x7fc4ee2a1f28>, vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "               max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "               oob_score=False, random_state=None, verbose=0,\n",
       "               warm_start=False),\n",
       "              n_jobs=1))],\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x7fc4ee2a1f28>, vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'clf': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       "            n_jobs=1),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_impurity_split': None,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 10,\n",
       " 'clf__estimator__n_jobs': 1,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'clf__n_jobs': 1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200, total=12.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 13.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200, total=12.7min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200, total=12.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=300, total=19.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=300, total=19.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=300, total=19.1min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200, total=11.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200, total=11.2min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=200, total=11.5min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=300, total=17.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=300 \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=300, total=17.1min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=300 \n"
     ]
    }
   ],
   "source": [
    "# parameters = {\n",
    "#     'clf__estimator__max_depth':[2],\n",
    "#     'clf__estimator__n_estimators':[20,50]\n",
    "#     }\n",
    "\n",
    "# parameters = {\n",
    "#     'vect__max_df': (0.5, 0.75, 1.0),\n",
    "#     'vect__ngram_range': ((1, 1), (1,2)),\n",
    "#     'vect__max_features': (None, 5000,10000),\n",
    "#     'tfidf__use_idf': (True, False)\n",
    "# }\n",
    "\n",
    "# parameters = {\n",
    "#     'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "#     'clf__estimator__bootstrap': (True, False)\n",
    "# }\n",
    "\n",
    "# parameters = { # try next\n",
    "#     'clf__estimator__n_estimators': [50, 100, 150],\n",
    "#     'clf__estimator__min_samples_split': [2, 3, 4]\n",
    "# }\n",
    "\n",
    "# parameters = { # try\n",
    "#         'clf__estimator__n_estimators': [100, 200],\n",
    "#         'clf__estimator__learning_rate': [0.1, 0.3]\n",
    "#     }\n",
    "\n",
    "parameters = { # try next\n",
    "    'clf__estimator__n_estimators': [200,300],\n",
    "    'clf__estimator__min_samples_split': [2,3]\n",
    "}\n",
    "\n",
    "# BEST PARAMS for [50,100] and [2,3] was {'clf__estimator__min_samples_split': 2, 'clf__estimator__n_estimators': 100}****\n",
    "# BEST PARAMS for [100,200] and [2,3] was {'clf__estimator__min_samples_split': 2, 'clf__estimator__n_estimators': 100}\n",
    "\n",
    "# parameters = { # try next\n",
    "# #     'clf__estimator__criterion': ['gini', 'entropy'], # In this, keep gini or entropy.\n",
    "#     'clf__estimator__max_depth': [2, 5], # Use only two [2,5,None]\n",
    "#     'clf__estimator__n_estimators': [100, 200], # Use only two [10,20,50]\n",
    "#     'clf__estimator__min_samples_leaf':[2, 5], # can be ignored [1,5,10]\n",
    "# }\n",
    "\n",
    "# scoring = {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score)}\n",
    "\n",
    "# cv = GridSearchCV(pipeline,param_grid=parameters,scoring=scoring,refit='accuracy') #If scoring not included, refit not needed and grid search would find best model based on estimator's score method, which is average accuracy\n",
    "\n",
    "# cv = GridSearchCV(pipeline,param_grid=parameters)\n",
    "\n",
    "scoring = make_scorer(f1_score, average='weighted')\n",
    "# cv = GridSearchCV(pipeline,param_grid=parameters, n_jobs=-1, verbose=2, scoring = ‘f1_weighted’) # the higher the verbose the more information\n",
    "\n",
    "# cv = GridSearchCV(pipeline,param_grid=parameters, n_jobs=-1, verbose=2, scoring = scoring)\n",
    "cv = GridSearchCV(pipeline,param_grid=parameters, n_jobs=-1, verbose=2) # better results when leave default scoring\n",
    "\n",
    "with active_session():\n",
    "    cv.fit(X_train,y_train)\n",
    "#     cv.fit(X_train_sample,y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_improved = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('train_classifier.pkl', 'wb') as file:\n",
    "#     pickle.dump(cv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train_classifier.pkl', \"rb\") as input_file:\n",
    "#     e = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_best = e.predict(X_test)\n",
    "# e.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_pred_improved, target_names=Y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_2 = get_metrics_summary(y_test,y_pred_improved)\n",
    "# metrics_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **COMPLETE THIS FUNCTION**\n",
    "\n",
    "def compare_metric(y_test,y_pred1,y_pred2,metric='f-1_score'):\n",
    "    metrics_summary = pd.DataFrame(index = category_names, columns = ['metric_old', 'metric_new'])\n",
    "    for i, c in enumerate(category_names):\n",
    "        if metric=='accuracy':\n",
    "#             metrics_summary.loc[c,'metric_old'] = accuracy_score(y_test.iloc[:,i],y_pred1[:,i])\n",
    "#             metrics_summary.loc[c,'metric_new'] = accuracy_score(y_test.iloc[:,i],y_pred2[:,i])\n",
    "            None\n",
    "        elif metric=='precision':\n",
    "#             metrics_summary.loc[c,'metric_old'] = precision_score(y_test.iloc[:,i],y_pred1[:,i])\n",
    "#             metrics_summary.loc[c,'metric_new'] = precision_score(y_test.iloc[:,i],y_pred2[:,i])\n",
    "            None\n",
    "        elif metric=='recall':\n",
    "#             metrics_summary.loc[c,'metric_old'] = recall_score(y_test.iloc[:,i],y_pred1[:,i])\n",
    "#             metrics_summary.loc[c,'metric_new'] = recall_score(y_test.iloc[:,i],y_pred2[:,i])\n",
    "            None\n",
    "        elif metric=='f-1_score':\n",
    "#             metrics_summary.loc[c,'metric_old'] = fbeta_score(y_test.iloc[:,i],y_pred1[:,i],beta=1)\n",
    "#             metrics_summary.loc[c,'metric_new'] = fbeta_score(y_test.iloc[:,i],y_pred2[:,i],beta=1)\n",
    "            metrics_summary.loc[c,'metric_old'] = precision_recall_fscore_support(y_test.iloc[:,i], y_pred1[:,i], average='weighted')[2] # 2 for 3rd entry in tuple for f-score\n",
    "            metrics_summary.loc[c,'metric_new'] = precision_recall_fscore_support(y_test.iloc[:,i], y_pred2[:,i], average='weighted')[2]\n",
    "        \n",
    "    metrics_summary['improved'] = metrics_summary['metric_new']>=metrics_summary['metric_old']\n",
    "    metrics_summary.loc['sum'] = metrics_summary.sum()\n",
    "\n",
    "#     metrics_summary.loc['average'] = metrics_summary.mean(axis=0)\n",
    "    \n",
    "    return metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_comparison = compare_metric(y_test,predicted,y_pred_improved)\n",
    "metrics_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_\n",
    "\n",
    "# 0.948995\t0.592643\t0.208286\t0.258425 with n_estimators = 200 and min_samples_split =2 as best from [100,200] and [2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1\n",
    "with active_session():\n",
    "    while a==1:\n",
    "        b=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try using different classifier - LEFT OFF HERE RUNNING***\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('vect',CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('clf',MultiOutputClassifier(AdaBoostClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2.fit(X_train,y_train)\n",
    "\n",
    "predicted2 = pipeline2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f-1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.788996</td>\n",
       "      <td>0.800466</td>\n",
       "      <td>0.965088</td>\n",
       "      <td>0.875102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.890733</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.62201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.993545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.767327</td>\n",
       "      <td>0.770068</td>\n",
       "      <td>0.627726</td>\n",
       "      <td>0.69165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.932381</td>\n",
       "      <td>0.641129</td>\n",
       "      <td>0.311765</td>\n",
       "      <td>0.419525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.95743</td>\n",
       "      <td>0.617486</td>\n",
       "      <td>0.353125</td>\n",
       "      <td>0.449304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.973874</td>\n",
       "      <td>0.62963</td>\n",
       "      <td>0.184783</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.979407</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0420168</td>\n",
       "      <td>0.0694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.97034</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.383387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child_alone</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.959889</td>\n",
       "      <td>0.725441</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.688172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.942677</td>\n",
       "      <td>0.805461</td>\n",
       "      <td>0.645691</td>\n",
       "      <td>0.716781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.942523</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.510714</td>\n",
       "      <td>0.604651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.988013</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.561798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.97787</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.297468</td>\n",
       "      <td>0.394958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.989396</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15942</td>\n",
       "      <td>0.241758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.964346</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>0.283951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.966344</td>\n",
       "      <td>0.740566</td>\n",
       "      <td>0.489097</td>\n",
       "      <td>0.589118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.870755</td>\n",
       "      <td>0.517094</td>\n",
       "      <td>0.142521</td>\n",
       "      <td>0.223453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.934993</td>\n",
       "      <td>0.422414</td>\n",
       "      <td>0.120988</td>\n",
       "      <td>0.1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.956508</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.202454</td>\n",
       "      <td>0.318072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.958045</td>\n",
       "      <td>0.650862</td>\n",
       "      <td>0.440233</td>\n",
       "      <td>0.525217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.979714</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.26087</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.99416</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.988781</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0491803</td>\n",
       "      <td>0.0759494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.993392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.988474</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0547945</td>\n",
       "      <td>0.0963855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.954972</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.113553</td>\n",
       "      <td>0.174648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.872599</td>\n",
       "      <td>0.837286</td>\n",
       "      <td>0.685915</td>\n",
       "      <td>0.754079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.957277</td>\n",
       "      <td>0.856338</td>\n",
       "      <td>0.572505</td>\n",
       "      <td>0.68623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.938067</td>\n",
       "      <td>0.790281</td>\n",
       "      <td>0.490476</td>\n",
       "      <td>0.605289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.986937</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.97034</td>\n",
       "      <td>0.880702</td>\n",
       "      <td>0.800638</td>\n",
       "      <td>0.838764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.984017</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.514019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.945443</td>\n",
       "      <td>0.496063</td>\n",
       "      <td>0.177966</td>\n",
       "      <td>0.261954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.851544</td>\n",
       "      <td>0.718571</td>\n",
       "      <td>0.39544</td>\n",
       "      <td>0.510142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average</th>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.55434</td>\n",
       "      <td>0.328284</td>\n",
       "      <td>0.396897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy precision     recall  f-1_score\n",
       "related                 0.788996  0.800466   0.965088   0.875102\n",
       "request                 0.890733      0.78   0.517241    0.62201\n",
       "offer                   0.993545         0          0          0\n",
       "aid_related             0.767327  0.770068   0.627726    0.69165\n",
       "medical_help            0.932381  0.641129   0.311765   0.419525\n",
       "medical_products         0.95743  0.617486   0.353125   0.449304\n",
       "search_and_rescue       0.973874   0.62963   0.184783   0.285714\n",
       "security                0.979407       0.2  0.0420168  0.0694444\n",
       "military                 0.97034  0.571429   0.288462   0.383387\n",
       "child_alone                    1         0          0          0\n",
       "water                   0.959889  0.725441   0.654545   0.688172\n",
       "food                    0.942677  0.805461   0.645691   0.716781\n",
       "shelter                 0.942523  0.740933   0.510714   0.604651\n",
       "clothing                0.988013  0.694444   0.471698   0.561798\n",
       "money                    0.97787    0.5875   0.297468   0.394958\n",
       "missing_people          0.989396       0.5    0.15942   0.241758\n",
       "refugees                0.964346  0.547619   0.191667   0.283951\n",
       "death                   0.966344  0.740566   0.489097   0.589118\n",
       "other_aid               0.870755  0.517094   0.142521   0.223453\n",
       "infrastructure_related  0.934993  0.422414   0.120988     0.1881\n",
       "transport               0.956508  0.741573   0.202454   0.318072\n",
       "buildings               0.958045  0.650862   0.440233   0.525217\n",
       "electricity             0.979714  0.545455    0.26087   0.352941\n",
       "tools                    0.99416         0          0          0\n",
       "hospitals               0.988781  0.166667  0.0491803  0.0759494\n",
       "shops                   0.993392         0          0          0\n",
       "aid_centers             0.988474       0.4  0.0547945  0.0963855\n",
       "other_infrastructure    0.954972  0.378049   0.113553   0.174648\n",
       "weather_related         0.872599  0.837286   0.685915   0.754079\n",
       "floods                  0.957277  0.856338   0.572505    0.68623\n",
       "storm                   0.938067  0.790281   0.490476   0.605289\n",
       "fire                    0.986937  0.459459   0.207317   0.285714\n",
       "earthquake               0.97034  0.880702   0.800638   0.838764\n",
       "cold                    0.984017  0.743243   0.392857   0.514019\n",
       "other_weather           0.945443  0.496063   0.177966   0.261954\n",
       "direct_report           0.851544  0.718571    0.39544   0.510142\n",
       "average                 0.947531   0.55434   0.328284   0.396897"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_adaboost = get_metrics_summary(y_test,predicted2)\n",
    "metrics_adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x7f8d6e45bf28>, vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "             learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "              n_jobs=1))],\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x7f8d6e45bf28>, vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'clf': MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "           learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "            n_jobs=1),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__algorithm': 'SAMME.R',\n",
       " 'clf__estimator__base_estimator': None,\n",
       " 'clf__estimator__learning_rate': 1.0,\n",
       " 'clf__estimator__n_estimators': 50,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator': AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "           learning_rate=1.0, n_estimators=50, random_state=None),\n",
       " 'clf__n_jobs': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] clf__estimator__learning_rate=0.5, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__learning_rate=0.5, clf__estimator__n_estimators=50, total= 1.5min\n",
      "[CV] clf__estimator__learning_rate=0.5, clf__estimator__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.5, clf__estimator__n_estimators=50, total= 1.4min\n",
      "[CV] clf__estimator__learning_rate=0.5, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__learning_rate=0.5, clf__estimator__n_estimators=50, total= 1.4min\n",
      "[CV] clf__estimator__learning_rate=0.5, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__learning_rate=0.5, clf__estimator__n_estimators=100, total= 2.7min\n",
      "[CV] clf__estimator__learning_rate=0.5, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__learning_rate=0.5, clf__estimator__n_estimators=100, total= 2.7min\n",
      "[CV] clf__estimator__learning_rate=0.5, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__learning_rate=0.5, clf__estimator__n_estimators=100, total= 2.6min\n",
      "[CV] clf__estimator__learning_rate=1.0, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__learning_rate=1.0, clf__estimator__n_estimators=50, total= 1.4min\n",
      "[CV] clf__estimator__learning_rate=1.0, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__learning_rate=1.0, clf__estimator__n_estimators=50, total= 1.4min\n",
      "[CV] clf__estimator__learning_rate=1.0, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__learning_rate=1.0, clf__estimator__n_estimators=50, total= 1.4min\n",
      "[CV] clf__estimator__learning_rate=1.0, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__learning_rate=1.0, clf__estimator__n_estimators=100, total= 2.7min\n",
      "[CV] clf__estimator__learning_rate=1.0, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__learning_rate=1.0, clf__estimator__n_estimators=100, total= 2.6min\n",
      "[CV] clf__estimator__learning_rate=1.0, clf__estimator__n_estimators=100 \n",
      "[CV]  clf__estimator__learning_rate=1.0, clf__estimator__n_estimators=100, total= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 27.1min finished\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f96150b26149>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0my_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "parameters2 = {\n",
    "    'clf__estimator__n_estimators': [50,100],\n",
    "    'clf__estimator__learning_rate': [0.5, 1.0]\n",
    "}\n",
    "\n",
    "cv2 = GridSearchCV(pipeline2,param_grid=parameters2, n_jobs=-1, verbose=2) # the higher the verbose the more information\n",
    "\n",
    "with active_session():\n",
    "    cv2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = cv2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f-1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.796527</td>\n",
       "      <td>0.804088</td>\n",
       "      <td>0.970907</td>\n",
       "      <td>0.879658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.892116</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.476569</td>\n",
       "      <td>0.605618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.99416</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.765637</td>\n",
       "      <td>0.785576</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.680361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.930229</td>\n",
       "      <td>0.67284</td>\n",
       "      <td>0.213725</td>\n",
       "      <td>0.324405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.956816</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.25625</td>\n",
       "      <td>0.368539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.974028</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.206573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.981405</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0168067</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.970493</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.314286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child_alone</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.962809</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.949285</td>\n",
       "      <td>0.799701</td>\n",
       "      <td>0.731874</td>\n",
       "      <td>0.764286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.943907</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.476786</td>\n",
       "      <td>0.593993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.987552</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.509091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.977563</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.170886</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.965883</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.239726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.966498</td>\n",
       "      <td>0.778378</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.56917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.87475</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.101296</td>\n",
       "      <td>0.174265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.938835</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.0716049</td>\n",
       "      <td>0.127193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.956816</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.168712</td>\n",
       "      <td>0.28133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.960504</td>\n",
       "      <td>0.738889</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.508604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.980175</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.287293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.994314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.989396</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0491803</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.993699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.98832</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0273973</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.956969</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.0695971</td>\n",
       "      <td>0.119497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.873675</td>\n",
       "      <td>0.868477</td>\n",
       "      <td>0.655693</td>\n",
       "      <td>0.747232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.956969</td>\n",
       "      <td>0.868035</td>\n",
       "      <td>0.557439</td>\n",
       "      <td>0.678899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.942062</td>\n",
       "      <td>0.806295</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.638543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.988013</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.264151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.972645</td>\n",
       "      <td>0.89317</td>\n",
       "      <td>0.813397</td>\n",
       "      <td>0.851419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.983095</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.43299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.946519</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.0903955</td>\n",
       "      <td>0.15534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.854772</td>\n",
       "      <td>0.780446</td>\n",
       "      <td>0.357704</td>\n",
       "      <td>0.490566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average</th>\n",
       "      <td>0.948786</td>\n",
       "      <td>0.600793</td>\n",
       "      <td>0.293858</td>\n",
       "      <td>0.365829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy precision     recall f-1_score\n",
       "related                 0.796527  0.804088   0.970907  0.879658\n",
       "request                 0.892116  0.830508   0.476569  0.605618\n",
       "offer                    0.99416         0          0         0\n",
       "aid_related             0.765637  0.785576        0.6  0.680361\n",
       "medical_help            0.930229   0.67284   0.213725  0.324405\n",
       "medical_products        0.956816     0.656    0.25625  0.368539\n",
       "search_and_rescue       0.974028  0.758621   0.119565  0.206573\n",
       "security                0.981405  0.333333  0.0168067     0.032\n",
       "military                0.970493  0.611111   0.211538  0.314286\n",
       "child_alone                    1         0          0         0\n",
       "water                   0.962809      0.75      0.675  0.710526\n",
       "food                    0.949285  0.799701   0.731874  0.764286\n",
       "shelter                 0.943907  0.787611   0.476786  0.593993\n",
       "clothing                0.987552  0.711864   0.396226  0.509091\n",
       "money                   0.977563  0.642857   0.170886      0.27\n",
       "missing_people          0.989857       0.6   0.130435  0.214286\n",
       "refugees                0.965883  0.673077   0.145833  0.239726\n",
       "death                   0.966498  0.778378   0.448598   0.56917\n",
       "other_aid                0.87475  0.623188   0.101296  0.174265\n",
       "infrastructure_related  0.938835  0.568627  0.0716049  0.127193\n",
       "transport               0.956816  0.846154   0.168712   0.28133\n",
       "buildings               0.960504  0.738889   0.387755  0.508604\n",
       "electricity             0.980175  0.604651   0.188406  0.287293\n",
       "tools                   0.994314         0          0         0\n",
       "hospitals               0.989396  0.214286  0.0491803      0.08\n",
       "shops                   0.993699         0          0         0\n",
       "aid_centers              0.98832  0.285714  0.0273973      0.05\n",
       "other_infrastructure    0.956969  0.422222  0.0695971  0.119497\n",
       "weather_related         0.873675  0.868477   0.655693  0.747232\n",
       "floods                  0.956969  0.868035   0.557439  0.678899\n",
       "storm                   0.942062  0.806295   0.528571  0.638543\n",
       "fire                    0.988013  0.583333   0.170732  0.264151\n",
       "earthquake              0.972645   0.89317   0.813397  0.851419\n",
       "cold                    0.983095  0.777778        0.3   0.43299\n",
       "other_weather           0.946519  0.551724  0.0903955   0.15534\n",
       "direct_report           0.854772  0.780446   0.357704  0.490566\n",
       "average                 0.948786  0.600793   0.293858  0.365829"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_adaboost_new = get_metrics_summary(y_test,y_pred2)\n",
    "metrics_adaboost_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_classifier_2.pkl', 'wb') as file:\n",
    "    pickle.dump(cv2, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
